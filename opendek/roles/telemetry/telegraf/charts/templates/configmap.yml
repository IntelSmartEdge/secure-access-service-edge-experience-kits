# SPDX-License-Identifier: Apache-2.0
# Copyright (c) 2022 Intel Corporation

apiVersion: v1
kind: ConfigMap
metadata:
  name: {{ .Values.telegraf.configMap }}
data:
  telegraf.conf: |+
    [agent]
      interval = "{{ .Values.telegraf.interval }}"
      round_interval = true
      metric_batch_size = 1000
      metric_buffer_limit = 10000
      collection_jitter = "0s"
      flush_interval = "5s"
      flush_jitter = "0s"
      precision = ""
      debug = false
      quiet = false
      logfile = ""
      hostname = "$HOSTNAME"
      omit_hostname = false

    # Read metrics from storage devices supporting S.M.A.R.T.
    [[inputs.smart]]
        ## Optionally specify the path to the smartctl executable
        # path_smartctl = "/usr/bin/smartctl"

        ## Optionally specify the path to the nvme-cli executable
        # path_nvme = "/usr/bin/nvme"

        ## Optionally specify if vendor specific attributes should be propagated for NVMe disk case
        ## ["auto-on"] - automatically find and enable additional vendor specific disk info
        ## ["vendor1", "vendor2", ...] - e.g. "Intel" enable additional Intel specific disk info
        # enable_extensions = ["auto-on"]

        ## On most platforms used cli utilities requires root access.
        ## Setting 'use_sudo' to true will make use of sudo to run smartctl or nvme-cli.
        ## Sudo must be configured to allow the telegraf user to run smartctl or nvme-cli
        ## without a password.
        use_sudo = true

        ## Skip checking disks in this power mode. Defaults to
        ## "standby" to not wake up disks that have stopped rotating.
        ## See --nocheck in the man pages for smartctl.
        ## smartctl version 5.41 and 5.42 have faulty detection of
        ## power mode and might require changing this value to
        ## "never" depending on your disks.
        # nocheck = "standby"

        ## Gather all returned S.M.A.R.T. attribute metrics and the detailed
        ## information from each drive into the 'smart_attribute' measurement.
        attributes = true

        ## Optionally specify devices to exclude from reporting if disks auto-discovery is performed.
        # excludes = [ "/dev/pass6" ]

        ## Optionally specify devices and device type, if unset
        ## a scan (smartctl --scan and smartctl --scan -d nvme) for S.M.A.R.T. devices will be done
        ## and all found will be included except for the excluded in excludes.
        # devices = [ "/dev/ada0 -d atacam", "/dev/nvme0"]

        ## Timeout for the cli command to complete.
        # timeout = "30s"

    [[outputs.prometheus_client]]
      ## Address to listen on.
      listen = ":{{ .Values.telegraf.port }}"

      ## Metric version controls the mapping from Telegraf metrics into
      ## Prometheus format.  When using the prometheus input, use the same value in
      ## both plugins to ensure metrics are round-tripped without modification.
      ##
      ##   example: metric_version = 1;
      ##            metric_version = 2; recommended version
      metric_version = 2

      ## Use HTTP Basic Authentication.
      # basic_username = "Foo"
      # basic_password = "Bar"

      ## If set, the IP Ranges which are allowed to access metrics.
      ##   ex: ip_range = ["192.168.0.0/24", "192.168.1.0/30"]
      # ip_range = ["192.168.0.0/24", "192.168.1.0/30"]

      ## Path to publish the metrics on.
      path = "/metrics"

      ## Expiration interval for each metric. 0 == no expiration
      # expiration_interval = "60s"

      ## Collectors to enable, valid entries are "gocollector" and "process".
      ## If unset, both are enabled.
      # collectors_exclude = ["gocollector", "process"]

      ## Send string metrics as Prometheus labels.
      ## Unless set to false all string metrics will be sent as labels.
      # string_as_label = true

      ## If set, enable TLS with the given certificate.
      tls_cert = "{{ .Values.certs.certsDest }}/tls.crt"
      tls_key = "{{ .Values.certs.certsDest }}/tls.key"

      ## Set one or more allowed client CA certificate file names to
      ## enable mutually authenticated TLS connections
      tls_allowed_cacerts = ["{{ .Values.certs.certsDest }}/ca.crt"]
      tls_cipher_suites = {{ .Values.certs.ciphers }}
      tls_min_version = "{{ .Values.certs.tls_min }}"
      tls_max_version = "{{ .Values.certs.tls_max }}"
      ## Export metric collection time.
      export_timestamp = true

    # Read metrics about disk IO by device
    [[inputs.diskio]]
      ## By default, telegraf will gather stats for all devices including
      ## disk partitions.
      ## Setting devices will restrict the stats to the specified devices.
      # devices = ["sda", "sdb"]
      ## Uncomment the following line if you need disk serial numbers.
      # skip_serial_number = false
      #
      ## On systems which support it, device metadata can be added in the form of
      ## tags.
      ## Currently only Linux is supported via udev properties. You can view
      ## available properties for a device by running:
      ## 'udevadm info -q property -n /dev/sda'
      ## Note: Most, but not all, udev properties can be accessed this way. Properties
      ## that are currently inaccessible include DEVTYPE, DEVNAME, and DEVPATH.
      device_tags = ["ID_FS_TYPE", "ID_FS_USAGE"]
      #
      ## Using the same metadata source as device_tags, you can also customize the
      ## name of the device via templates.
      ## The 'name_templates' parameter is a list of templates to try and apply to
      ## the device. The template may contain variables in the form of '$PROPERTY' or
      ## '${PROPERTY}'. The first template which does not contain any variables not
      ## present for the device is used as the device name tag.
      ## The typical use case is for LVM volumes, to get the VG/LV name instead of
      ## the near-meaningless DM-0 name.
      # name_templates = ["$ID_FS_LABEL","$DM_VG_NAME/$DM_LV_NAME"]

    [[inputs.redfish]]
      ## For quick check proper work of redfish plugin, you can do a mockup:
      ## Mockup must be preformed on HOST!
      ## 1. Get a source code: git clone https://opendev.org/x/python-redfish.git
      ## 2. Go into dmtf/mockup_0.99.0a folder.
      ## 3. Run ./buildImage.sh and ./run-redfish-simulator.sh
      ## 4. Check that a container is running and listening on port 8000, by command: docker ps
      ## 5. Now run Telegraf with redfish plugin.

      ## Redfish API Base URL.
      address = "http://localhost:8000/redfish/v1"

      ## Credentials for the Redfish API.
      username = "root"
      password = "password123456"

      ## System Id to collect data for in Redfish APIs.
      computer_system_id="1"

      ## Amount of time allowed to complete the HTTP request
      # timeout = "5s"

      ## Optional TLS Config
      # tls_ca = "/etc/telegraf/ca.pem"
      # tls_cert = "/etc/telegraf/cert.pem"
      # tls_key = "/etc/telegraf/key.pem"
      ## Use TLS but skip chain & host verification
      # insecure_skip_verify = false

    # Returns ethtool statistics for given interfaces
    [[inputs.ethtool]]
      ## List of interfaces to pull metrics for
      # interface_include = ["eth0"]

      ## List of interfaces to ignore when pulling metrics.
      # interface_exclude = ["eth1"]

    # Gather metrics about network interfaces
    [[inputs.net]]
      ## By default, telegraf gathers stats from any up interface (excluding loopback)
      ## Setting interfaces will tell it to gather these explicit interfaces,
      ## regardless of status. When specifying an interface, glob-style
      ## patterns are also supported.
      ##
      # interfaces = ["eth*", "enp0s[0-1]", "lo"]
      ##
      ## On linux systems telegraf also collects protocol stats.
      ## Setting ignore_protocol_stats to true will skip reporting of protocol metrics.
      ##
      # ignore_protocol_stats = false
      ##

    [[inputs.disk]]
      ## By default stats will be gathered for all mount points.
      ## Set mount_points will restrict the stats to only the specified mount points.
      # mount_points = ["/"]

      ## Ignore mount points by filesystem type.
      ignore_fs = ["tmpfs", "devtmpfs", "devfs", "iso9660", "overlay", "aufs", "squashfs"]

    # Read metrics about memory usage
    [[inputs.mem]]
      # no configuration

    [[inputs.temp]]
      # no configuration

    # Read metrics from the bare metal servers via IPMI
    [[inputs.ipmi_sensor]]
      ## optionally specify the path to the ipmitool executable
      # path = "/usr/bin/ipmitool"
      ##
      ## Setting 'use_sudo' to true will make use of sudo to run ipmitool.
      ## Sudo must be configured to allow the telegraf user to run ipmitool
      ## without a password.
      use_sudo = true
      ##
      ## optionally force session privilege level. Can be CALLBACK, USER, OPERATOR, ADMINISTRATOR
      # privilege = "ADMINISTRATOR"
      ##
      ## optionally specify one or more servers via a url matching
      ##  [username[:password]@][protocol[(address)]]
      ##  e.g.
      ##    root:passwd@lan(127.0.0.1)
      ##
      ## if no servers are specified, local machine sensor stats will be queried
      ##
      # servers = ["1:123@lan(192.168.1.1)"]

      ## Recommended: use metric 'interval' that is a multiple of 'timeout' to avoid
      ## gaps or overlap in pulled data
      interval = "30s"

      ## Timeout for the ipmitool command to complete. Default is 20 seconds.
      timeout = "20s"

      ## Schema Version: (Optional, defaults to version 1)
      metric_version = 2

      ## Optionally provide the hex key for the IMPI connection.
      # hex_key = ""

      ## If ipmitool should use a cache
      ## for me ipmitool runs about 2 to 10 times faster with cache enabled on HP G10 servers (when using ubuntu20.04)
      ## the cache file may not work well for you if some sensors come up late
      # use_cache = false

      ## Path to the ipmitools cache file (defaults to OS temp dir)
      ## The provided path must exist and must be writable
      # cache_path = ""
